# ğŸ§  Sentiment Analysis using Multinomial Naive Bayes

An end-to-end Natural Language Processing (NLP) project that classifies text into Positive or Negative sentiment using Machine Learning.

---

## ğŸ“ŒProject Overview

This project implements a complete Sentiment Analysis pipeline using **Multinomial Naive Bayes**, a probabilistic machine learning algorithm well-suited for text classification tasks.

The system processes raw textual data, converts it into numerical features using vectorization techniques, and trains a classification model to predict sentiment polarity.

---

## ğŸš€ Features

- Text preprocessing pipeline
- Feature extraction using TF-IDF / Bag of Words
- Multinomial Naive Bayes classifier
- Model evaluation using multiple performance metrics
- Sentiment prediction for custom user input

---

## ğŸ—ï¸ Project Workflow

Raw Text  
â†’ Text Cleaning & Preprocessing  
â†’ Feature Extraction (TF-IDF / CountVectorizer)  
â†’ Train-Test Split  
â†’ Model Training (MultinomialNB)  
â†’ Evaluation  
â†’ Prediction  

---

## ğŸ› ï¸ Tech Stack

- **Python**
- **Pandas**
- **Matplotlib**
- **Seaborn**
- **NLTK**
- **Scikit-learn**
- **Jupyter Notebook**

---

## ğŸ“‚ Project Structure

Sentiment_Analysis_final.ipynb  â†’ Main notebook  
README.md                       â†’ Project documentation  

---

## âš™ï¸ Implementation Details

### 1. Data Preprocessing

- Convert text to lowercase  
- Remove punctuation & special characters  
- Remove stopwords  
- Tokenization  
- Stemming / Lemmatization  

This step removes noise and prepares clean input for model training.

---

### 2. Feature Engineering

Text data is converted into numerical format using:

- **Bag of Words (CountVectorizer)**
- **TF-IDF (Term Frequency â€“ Inverse Document Frequency)**

TF-IDF improves model performance by reducing the weight of common words.

---

### 3. Model Used

**Multinomial Naive Bayes (MultinomialNB)**

This probabilistic classifier is based on Bayesâ€™ Theorem and works efficiently for text classification problems involving word frequency features.

---

### 4. Model Evaluation
The model is evaluated using the following metrics:

#### ğŸ”¹ Accuracy Score
Measures the percentage of correct predictions out of total predictions.

Accuracy = Correct Predictions / Total Predictions  

Example:  
If accuracy = 0.80 â†’ The model correctly predicts 80% of the data.

---

#### ğŸ”¹ Confusion Matrix

A Confusion Matrix shows detailed classification results:

- True Positive (TP)  
- True Negative (TN)  
- False Positive (FP)  
- False Negative (FN)  

It helps identify where the model makes mistakes.

---

#### ğŸ”¹ Precision

Precision = TP / (TP + FP)  

Measures how many predicted positive values are actually positive.  
High precision means fewer false positives.

---

#### ğŸ”¹ Recall

Recall = TP / (TP + FN)  

Measures how many actual positive values were correctly predicted.  
High recall means fewer missed positive cases.

---

#### ğŸ”¹ F1-Score

F1 = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)  

F1-score balances both Precision and Recall.  
It is especially useful when the dataset is imbalanced.

---

## ğŸ§ª Example Prediction

### Enter a review:  The product good

### The review: 'The product good' is predicted Postive Review
---